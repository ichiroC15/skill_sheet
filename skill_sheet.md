## プロフィール
GitHub: @IchiroC15

## 職務
求人アグリゲーションサイトの開発・運用

主に求人提供元サイトとの連携、他アグリゲーションサイトへの求人情報送信を担当

## 自己PR
前職では求人アグリゲーションサイト(会員数100万人以上、総求人数40万以上)の開発・運用を行った。組織のメンバー4人は皆エンジニアで、開発・運用はもちろん、企画からコードレビュー、CSまで全員で対応していた。その中でも主に求人提供元サイトとの連携、他アグリゲーションサイトへの求人情報送信を担当した(詳細は職歴欄に記載)。

### 【 キャッチアップ力】
- プログラミングを始めたのは2019年1月と日が浅いが、現職就任後はプライベートの時間も使って常に技術の習得につとめてきた。プロダクトのコードを読み把握することはもちろん、業務で利用するフレームワーク(Rails)への理解やテスト(Rspec)の手法も書籍を用いて自主的に学習してきた。

-入社後3ヶ月に他求人アグリゲーションサイトとの連携を担当したことを皮切りに、他社との新規連携際に関わる開発を任されている。2020年度からはPHPFuelを用いた開発に加え、GoogleTagmanagerやGoogleSearchConsoleの運用も行っている。

### 【 サービスの改善への意識】
- サービスの改善には貪欲であり、様々なアイデアを自発的に提案して開発に携わってきた。DBとGoogleAnalyticsを毎日欠かさずチェックすることで施策の有効性を分析し、さらなる改善点を見つけてプロダクトの成⻑に貢献しようとしている。

- 一方でユーザー目線に立つことも意識し、新着求人を通知するメルマガや応募結果通知の文面の改善も積極的に提案して開発を行ってきた。

### 【 文章力】
- もともと文系出身であること、文化遺産・日本庭園のライターとして活動していたことから、文章を書くことに関しては苦にならない。各種ドキュメントの作成といったの文書化作業も厭わずに率先してこなしてきた。

## やりたいこと
### 【 目指すエンジニア像】
- 社会課題を技術で解決できるエンジニアを目指したい。そのために技術的引き出しを多くもつこと、そして適切な技術を選択できる深い理解が必要と考えている。同時に課題を正確に分析し把握できる能力も身に付け、俯瞰的にサービスを見ることができるエンジニアでありたい。

### 【現状の課題】
- スピードを重視するあまり場当たり的な設計になっていた反省もあり、ドメイン駆動設計を通じた設計思想の理解とデザインパターンの再学習をすすめている。

- Ruby, PHPといった動的型付け言語を現職で使用する一方で、厳格なメモリの管理や堅牢なシステムへの関心が高まっており、Go言語の自主的な学習と勉強会への参加を行っている。

- 情報処理の基本的理解の乏しさを実感しており、基本技術者試験の取得に向けて勉強中。

## 保有技術
**Ruby**, PHP, Java, **Ruby on Rails**, Fuel, HTML, CSS, **CentOS**, **MySQL**, Redis, Vagrant, Ansible, Solr

## 得意分野
外部サービスとのファイル・APIを通じた連携処理の作成

## 主な担当プロジェクト

### GoogleIndexingAPIへの求人情報自動送信機能を実装し、新着求人をGoogleしごと検索に即時反映
【時期】2020/12 ~ 2021/1

【使用言語等】Ruby(2.6.4), Ruby on Rails(6.0.0), MySQL(5.7.29), CentOS(6.7), GoogleSearchConsole, GoogleCloudPlatform

【担当工程】要件定義, 設計, 実装, 単体テスト, 統合テスト

【課題】サイトマップのクローリング依頼のみでは、Googleしごと検索に新着求人が反映されるのに時間がかかってしまう

【解決策】GoogleIndexingAPIへ新着の求人詳細ページURLを自動送信し、随時Googleしごと検索に求人情報を反映

【問題点】
1. 送信すべきURLが毎日数万件単位であるため、サーバの負荷を考えると1件ずつ送信するわけにはいかない
2. Googleの認証アカウント1件につき、送信できる求人が1日あたり200件に制限される
3. Rubyで実装された公式ライブラリの解説が充実しておらず、テストの方法が不明

【対応】
[問題点1]
- 1件ずつ送信するだけならすぐに実装できるが、前述の事情もありまとめて送信できるよう公式ドキュメントを隅々まで読み込み対応策を練った。
- 公式ライブラリで提供されるbatch(一斉送信)処理を用いて実装。実装の例が英語記事を含めてネット上でも見つからなかったため、公式ライブラリのコードを開発環境でひとつひとつ読み解きながら作業を進めた。
- おかげでGoogleIndexingAPIの仕様が代わっても、ライブラリの更新次第でコードを直さずに対応できるようになった。

[問題点2]
- 複数のアカウントを取得し、それぞれのアカウントで認証→送信処理を行うことで求人送信件数を増加させた。
- 認証処理部分は他のGoogleAPIを使用する可能性を考慮して送信処理から切り出し、後にGoogleAnalyticsとAPIを通じて連携する話が出た際には開発の簡易化に貢献。

[問題点3]
- 送信処理を自前のコードでラッピングし、本番環境以外では送信するリクエストのbodyをJSON形式で表示させて簡易的にテストできるように設定。
- APIからエラーコードが返却された際は、そのエラーコードに合わせて対応を自動化した。求人404エラー/求人送信済みエラー→ログ記録のみ、認証エラー→メール通知、等。

### Googleしごと検索との連携による、新規ユーザー獲得及び応募数の増加
【時期】2020/10 ~ 2020/11

【使用言語等】PHP(7.2.29), Fuel(1.8.2), MySQL(5.7.29), CentOS(7.0), GoogleTagManager, GoogleSearchConsole

【担当工程】要件定義, 設計, 実装, 統合テスト, 運用

【課題】コロナ禍における新規ユーザー及び応募数の減少

【解決策】求人情報詳細ページにGoogleしごと検索タグを追加し、Googleしごと検索からの流入を狙う

【問題点】
1. Googleしごと検索の基準通りに求人情報を記述しなければならない
2. 一部Googleしごと検索に載せたくない求人がある
3. 求人情報は項目ごとにDBのカラムに分けて保存しているが、求人の提携元サイトごとにカラムの利用の仕方が異なっている

【対応】
[問題点1]
- まずはGoogleしごと検索のドキュメントを整理し、必要な項目が自社サイトでのどの項目に該当するかを文書化。メンバーのチェックを受けた上で開発を開始し要件定義漏れによる開発遅延を防ぐ。
- 禁止文字、記号はDBで管理し、今後追加があってもコードを変更せず対応できるようにした。

[問題点2]
- タグの表示/非表示をフィルタリングする機能を設定することで対応。
- また、フィルタリング条件をJSONで{"項目名1": ["キーワードa", "キーワードb"], "項目名2": ["キーワードc"]}のように指定することで、複雑なAND, OR条件を指定できるようになった。

[問題点3]
- PHP及びPHPFuelは始めて使用する技術だったため、プライベートの時間を用いて書籍による学習時間を設けて迅速な開発に努めた。
- Strategyパターンを利用して、求人の掲載元サイトごとに表示する項目を個別に設定する処理を追加した。
- Rubyのデザインパターンとはだいぶ勝手が違ったが、異なる言語で実装することで、ただのコピーにとどまらずデザインパターンへの理解がさらに深まったと感じている。

### サイトマップの自動作成機能を実装し、Googleしごと検索との連携に備える
【時期】2020/6 ~ 2020/8

【使用言語等】Ruby(2.6.4), Ruby on Rails(6.0.0), MySQL(5.7.29), CentOS(6.7, 7.0), GoogleSearchConsole

【担当工程】要件定義, 設計, 実装, 単体テスト, 統合テスト, 運用

【課題】毎日求人が追加・更新されるサービスの仕様上、掲載元サイトから求人情報を取り込む度にサイトマップを更新する必要がある

【解決策】既存のGemでは作成に時間がかかり頻繁な運用ができないため、完全新規で機能を実装
- 有効な求人情報詳細ページ一覧の取得/サイトマップ作成/サイトマップインデックスファイルの更新/クローラーへの通知

【問題点】
1. 既存のライブラリでは現在のページ全てに対するサイトマップを作成してしまうため、数十万の求人情報詳細ページを持つサービスではサイトマップ作成にかなりの時間がかかる
2. 毎日複数回求人の入れ替わりが発生するため、その都度サイトマップを更新する必要がある

【対応】
[問題点1, 2]
- 既存のライブラリでは対応できないと判断し、サイトマップを部分的に更新する機能を独自で開発することに決定。
- 複雑な処理だったために設計にかける時間を多くとり、レビューをもらった上で開発に入った。処理の流れをまず整理し、必要な機能を以下に切り分けている。
- 有効な求人情報詳細ページ一覧の取得 / サイトマップ作成 / サイトマップインデックスファイルの更新 / クローラーへの通知

【工夫した点】
- テスト駆動開発を採用し、関数型を意識してメソッドを作成すること、メソッドの粒度を細かくすることを重視した。結果的に開発中に不具合が発見でき、リリース後の不具合もなく運用することができた。
- 今回要求されたのは求人詳細ページのサイトマップ作成だったが、今後サイトマップ作成の対象が拡張することを考慮し設計を行った。引数にサイトマップに記載するURLの配列をとることで、どんなURLに対してもサイトマップの作成が実行できる。
- 求人掲載元サイトからの求人情報をDBにインポートした後に処理が走るよう、Resqueを用いて自動化。

### 大手求人サービスとの新規連携による、総求人数増加と求人の多様性獲得
【時期】2020/2 ~ 2020/3

【使用言語等】Ruby(2.3.3), Ruby on Rails(5.0.0), MySQL(5.7.29), CentOS(6.7)

【担当工程】要件定義, 設計, 実装, 単体テスト, 統合テスト

【課題】求人掲載元サイトの求人数減による、総求人数の減少と画一化

【解決策】大手求人サービスと新規に連携し、総求人数を増やし求人を多様化
- 求人情報CSVファイルを受信するためのFTPサーバを設定
- 受け取ったCSVファイルを自社仕様のCSVファイルに変換し、DBにインポート
- 自社サイトからの応募時、応募者情報を連携先のAPIに送信
- APIからのレスポンスを受け取り、応募者へ結果通知メールを送る

【問題点】
1. 外部サービスとの連携であるため、リリース後の不具合発生が許されない
2. 求人情報送信や求人ファイルの受信等のテストに関しては、連携先とスケジュールを合わせる必要がある

【対応】
[問題点1]
- 新規連携先の求人情報における表示項目のすりあわせ(ドキュメント作成→社内レビュー→疑問点洗い出し→問い合わせ)をまず優先して行った。
- 開発前に実装すべきものをリスト化し、既存コードとの共通化から検討した。

[問題点2]
- 連携先との交渉があり開発に時間がかかるもの、自社内のみで開発を進められるものを細分化し、提携先のスケジュールに合わせて開発の優先度を調整した。実装した機能は以下になる。
  - 求人情報CSVファイルを受信するためのFTPサーバを設定
    →連携先とのスケジューリング必要
  - 受け取ったCSVファイルを自社仕様のCSVファイルに変換し、DBにインポート
    →テスト用のCSVファイルさえあれば開発可能
  - 自社サイトからの応募時、応募者情報を連携先のAPIに送信
    →送信処理のみスケジューリング必須
  - 提携先のAPIからのレスポンスを受け取り、応募者へ結果通知メールを送る
    →API仕様書があれば開発可能


### 採用祝い金制度の導入による高単価求人への誘導
【時期】2019/11 ~ 2019/12

【使用言語等】Ruby(2.3.3), Ruby on Rails(5.0.0), MySQL(5.7.29), CentOS(6.7)

【担当工程】要件定義, 設計, 実装, 単体テスト, 統合テスト, 運用

【課題】一部低単価求人への応募の集中

【対応】求人掲載元が設けている採用祝い金の情報を自社サイトにも掲載し、応募の分散を図る

【工夫した点】
- 自社サイト側で採用祝い金情報の表示を制御するフィルタリング機能
- 運用効率を考慮し、管理画面で上記フィルタリング条件をJSONで入力できるように
- 管理画面でのフィルタリング条件におけるJSONのバリデーション設定

### 他求人アグリゲーションサイトとの連携による、新規ユーザーの獲得と応募数増加
【時期】2019/7 ~ 2020/9

【使用言語等】Ruby(2.3.3), Ruby on Rails(5.0.0), MySQL(5.7.29), CentOS(6.7)

【担当工程】要件定義, 設計, 実装, 単体テスト, 統合テスト, 運用

【課題】メールマガジンの訴求鈍化による、新規ユーザーの減少と応募減

【解決策】大手求人アグリゲーションサービスと連携し、新規ユーザーの獲得と応募数増加を狙う
- DBの求人情報を読み込み、XML/CSVファイルに出力
- FTPサーバを設定し連携先とファイルをやり取り

【問題点】
1. 数十万の求人を読み込みファイルに出力するため、パフォーマンスを意識しなければならない
2. 大手求人アグリゲーションを通じた運用には課金が必要なため、CV率が要求される

【対応】
[問題点1]
- 時間的な成約が緩かったため、処理案を複数作成し、各々でパフォーマンスを測定して一番良いものを採用するかたちをとった。
- カラムを限定して全有効求人を配列として一括で読み込むことで、DBからデータを読み込む時間を短縮。
- さらに求人の提供元ごとの分岐処理も、各求人提供元ごとに設定したモジュールを読み込んで処理することで高速化。(Strategyパターンを使用すると、インスタンスが分岐処理ごとに作成されるため時間がかかってしまう)

[問題点2]
- 問題点1でも言及したとおり、求人の掲載元サイトごとに分岐処理を行い、表示する項目を最適化した。
- 求人の応募単価ごとに送信/非送信をフィルタリングできるよう設定し、運用での赤字が出ないよう調整した。

【工夫した点】
- 連携先が今後増加することを見越してコードを共通化し、2社目との連携にかかる工数を大幅に削減した。
